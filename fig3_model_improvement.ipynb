{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "#import custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/frederickkorbel/Documents/projects/paper/mlcis/utils')\n",
    "\n",
    "import integrated_gradients as ig\n",
    "import metaplot\n",
    "\n",
    "#set seaborn style\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(df, model, test_seq, obs_col, output_col='pred'):\n",
    "    '''Predict mean ribosome load using model and test set UTRs'''\n",
    "    \n",
    "    # Scale the test set mean ribosome load\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df[obs_col].values.reshape(-1,1))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(test_seq).reshape(-1,1)\n",
    "    \n",
    "    # Inverse scaled predicted mean ribosome load and return in a column labeled 'pred'\n",
    "    df.loc[:,output_col] = scaler.inverse_transform(predictions)\n",
    "    return df\n",
    "\n",
    "\n",
    "def r2(x,y):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    return r_value**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=white size=20> Defining Datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the two datasets for subsequent training\n",
    "train_synthetic=pd.read_csv('/Users/frederickkorbel/Documents/projects/paper/mlcis/data/random_train.csv.gz', compression='gzip', index_col=[0])\n",
    "train_human=pd.read_csv('/Users/frederickkorbel/Documents/projects/paper/mlcis/data/human_train.csv', index_col=[0])\n",
    "\n",
    "#the dataset to optimize for and test performance on\n",
    "test_human=pd.read_csv('/Users/frederickkorbel/Documents/projects/paper/mlcis/data/human_test.csv', index_col=[0])\n",
    "\n",
    "#one-hot-encode all datasets\n",
    "train_synthetic_seq=metaplot.one_hot_encode(train_synthetic)\n",
    "train_human_seq=metaplot.one_hot_encode(train_human)\n",
    "\n",
    "test_human_seq=metaplot.one_hot_encode(test_human)\n",
    "\n",
    "#scale MRL values\n",
    "test_human.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(test_human.loc[:,'rl'].values.reshape(-1,1))\n",
    "train_human.loc[:,'scaled_rl'] = preprocessing.StandardScaler().fit_transform(train_human.loc[:,'rl'].values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters to optimize via grid search\n",
    "epochs_hum=[1,3,5,7,9]\n",
    "epochs_syn=[1,2,3]\n",
    "\n",
    "#perform the grid search to find the optimal number of training epochs\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "history = LossHistory()\n",
    "\n",
    "\n",
    "\n",
    "class OptimizedModel(keras_tuner.HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(50, 4), padding='same', filters=120, kernel_size=8))\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(50, 1), padding='same', filters=120, kernel_size=8))\n",
    "        model.add(Conv1D(activation=\"relu\", input_shape=(50, 1), padding='same', filters=120, kernel_size=8))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(40))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('linear'))\n",
    "\n",
    "        adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        \n",
    "\n",
    "        model.fit(*args, batch_size=128, epochs=hp.Choice('epochs', epochs_hum), **kwargs)\n",
    "\n",
    "        return model #.fit(*args, batch_size=128, epochs=hp.Choice('epochs', epochs_hum), **kwargs)\n",
    "\n",
    "tuner=keras_tuner.RandomSearch(\n",
    "    hypermodel=OptimizedModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    directory='/Users/frederickkorbel/Documents/projects/paper/mlcis/models/tune_mrl_model',\n",
    "    project_name='tune_mrl_model'\n",
    ")\n",
    "\n",
    "tuner.search(train_human_seq,train_human['rl'], validation_data=(test_human_seq, test_human['rl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_hum=[1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "class OptimizedModel(keras_tuner.HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "        return keras.models.load_model('/Users/frederickkorbel/Documents/projects/paper/mlcis/models/main_MRL_model.hdf5')\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        #model.fit(*args, batch_size=128, epochs=hp.Choice('epochs', epochs_syn), **kwargs)\n",
    "        return model.fit(*args, batch_size=128, epochs=hp.Choice('epochs', epochs_hum), **kwargs)\n",
    "\n",
    "\n",
    "tuner=keras_tuner.RandomSearch(\n",
    "    hypermodel=OptimizedModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    directory='/Users/frederickkorbel/Documents/projects/paper/mlcis/models/tune_mrl_model',\n",
    "    project_name='tune_mrl_model')\n",
    "\n",
    "tuner.search(train_human_seq,train_human['rl'], validation_data=(test_human_seq, test_human['rl']))\n",
    "\n",
    "tuner.results_summary(num_trials=10)\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot r2 of all generated models as heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance of the optimized model\n",
    "OPT_human_test_pred=test_data(test_human, best_model, 'rl', test_human_seq)\n",
    "\n",
    "r_2 = r2(test_human['rl'], OPT_human_test_pred['pred'])\n",
    "print('r-squared = ', r_2)\n",
    "g, ax = plt.subplots(figsize=(6,6))\n",
    "g = sns.regplot(data = OPT_human_test_pred, x = 'rl', y = 'pred', scatter_kws={'alpha':0.5}, line_kws={\"color\": \"black\"})\n",
    "g.set(ylim=(0,9), xlim=(0,9), xticks = range(1,10,1), yticks = range(1,10,1))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel('Measured MRL', fontsize=20)\n",
    "plt.ylabel('Predicted MRL', fontsize=20)\n",
    "sns.despine()\n",
    "\n",
    "#save predictions\n",
    "#OPT_human_test_pred.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare performance of best model to O5P (original MRL model) and hMRL (model trained on human 5'UTRs)\n",
    "\n",
    "mrl_model=\n",
    "hmrl_model=\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('mlcis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bfa4aa8d2cf613342596a6d988858e43b151c27750d9d6d65cd918aed0d614"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
